testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
library(forecast)
fit<-bats(tstrain)
fcast<-forecast(fit)
fcast #tells you 95 and 85
library("forecast")
library("forecast", lib.loc="~/R/win-library/3.1")
fit<-bats(tstrain)
install.packages("forecast")
install.packages("forecast")
library(lubridate)  # For year() function below
dat = read.csv("gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
library(forecast)
fit<-bats(tstrain)
fcast<-forecast(fit)
fcast #tells you 95 and 85
library(lubridate)  # For year() function below
dat = read.csv("gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
library(forecast)
fit<-bats(tstrain)
fcast<-forecast(fit)
fcast #tells you 95 and 85
install.packages(timeDate)
install.packages("timeDate")
install.packages("timeDate")
library(forecast)
sessionInfo
sessionInfo()
install.packages(tseries)
install.packages("tseries")
install.packages("tseries")
library("stats", lib.loc="C:/Program Files/R/R-3.1.1/library")
library("tools", lib.loc="C:/Program Files/R/R-3.1.1/library")
library("utils", lib.loc="C:/Program Files/R/R-3.1.1/library")
library("datasets", lib.loc="C:/Program Files/R/R-3.1.1/library")
library("class", lib.loc="C:/Program Files/R/R-3.1.1/library")
library("zoo", lib.loc="~/R/win-library/3.1")
library("timeDate", lib.loc="~/R/win-library/3.1")
library("rstudio", lib.loc="~/R/win-library/3.1")
library("rCharts", lib.loc="~/R/win-library/3.1")
library("randomForest", lib.loc="~/R/win-library/3.1")
library("latticeExtra", lib.loc="~/R/win-library/3.1")
library("lubridate", lib.loc="~/R/win-library/3.1")
library("gbm", lib.loc="~/R/win-library/3.1")
library("gdata", lib.loc="~/R/win-library/3.1")
library("ggplot2", lib.loc="~/R/win-library/3.1")
library("glmnet", lib.loc="~/R/win-library/3.1")
library("gplots", lib.loc="~/R/win-library/3.1")
library("caret", lib.loc="~/R/win-library/3.1")
library("devtools", lib.loc="~/R/win-library/3.1")
library("e1071", lib.loc="~/R/win-library/3.1")
library("elasticnet", lib.loc="~/R/win-library/3.1")
library("ElemStatLearn", lib.loc="~/R/win-library/3.1")
library("forecast", lib.loc="~/R/win-library/3.1")
detach("package:forecast", unload=TRUE)
library("forecast", lib.loc="~/R/win-library/3.1")
detach("package:forecast", unload=TRUE)
remove.packages("forecast", lib="~/R/win-library/3.1")
install.packages("forecast")
library("forecast", lib.loc="~/R/win-library/3.1")
formatDL
formatDL()
install.packages("forecast",dependencies = TRUE)
install.packages("forecast", dependencies = TRUE)
library("forecast", lib.loc="~/R/win-library/3.1")
install.packages("forecast", repos=c("http://rstudio.org/_packages", "http://cran.rstudio.com"))
library("forecast", lib.loc="~/R/win-library/3.1")
library("Rcpp", lib.loc="~/R/win-library/3.1")
library("forecast", lib.loc="~/R/win-library/3.1")
attach(forecast)
.libPaths()
install.packages(c("caret", "formatR", "labeling", "markdown", "swirl", "xlsxjars"))
library("forecast", lib.loc="~/R/win-library/3.1")
remove.packages("forecast", lib="~/R/win-library/3.1")
install.packages("forecast")
library("forecast", lib.loc="~/R/win-library/3.1")
detach("package:forecast", unload=TRUE)
library("forecast", lib.loc="~/R/win-library/3.1")
library("forecast", lib.loc="~/R/win-library/3.1")
install.packages("base")
install.packages("base")
install.packages("base")
library("base64enc", lib.loc="~/R/win-library/3.1")
library("caret", lib.loc="~/R/win-library/3.1")
library("forecast", lib.loc="~/R/win-library/3.1")
detach("package:timeDate", unload=TRUE)
library("timeDate", lib.loc="~/R/win-library/3.1")
library("tseries", lib.loc="~/R/win-library/3.1")
library("UsingR", lib.loc="~/R/win-library/3.1")
library("TTR", lib.loc="~/R/win-library/3.1")
library("zlibbioc", lib.loc="~/R/win-library/3.1")
library("yaml", lib.loc="~/R/win-library/3.1")
library("xtable", lib.loc="~/R/win-library/3.1")
library("XML", lib.loc="~/R/win-library/3.1")
library("xlsx", lib.loc="~/R/win-library/3.1")
library("xlsxjars", lib.loc="~/R/win-library/3.1")
library("tree", lib.loc="~/R/win-library/3.1")
library("whisker", lib.loc="~/R/win-library/3.1")
library("scrypt", lib.loc="~/R/win-library/3.1")
library("sp", lib.loc="~/R/win-library/3.1")
library("labeling", lib.loc="~/R/win-library/3.1")
library("knitr", lib.loc="~/R/win-library/3.1")
library("jsonlite", lib.loc="~/R/win-library/3.1")
library("jpeg", lib.loc="~/R/win-library/3.1")
library("iterators", lib.loc="~/R/win-library/3.1")
library("httr", lib.loc="~/R/win-library/3.1")
library("glmnet", lib.loc="~/R/win-library/3.1")
library("googleVis", lib.loc="~/R/win-library/3.1")
library("gplots", lib.loc="~/R/win-library/3.1")
library("gsubfn", lib.loc="~/R/win-library/3.1")
library("fpp", lib.loc="~/R/win-library/3.1")
library("fracdiff", lib.loc="~/R/win-library/3.1")
library("gbm", lib.loc="~/R/win-library/3.1")
detach("package:forecast", unload=TRUE)
library("forecast", lib.loc="~/R/win-library/3.1")
detach("package:forecast", unload=TRUE)
library("forecast", lib.loc="~/R/win-library/3.1")
formatDL(nm, txt, indent = max(nchar(nm, "w")) + 3)
library(caret)
library(lubridate)  # For year() function below
dat = read.csv("gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
library(forecast)
fit<-bats(tstrain)
fcast<-forecast(fit)
fcast #tells you 95 and 85
View(testing)
View(training)
library("forecast", lib.loc="~/R/win-library/3.1")
detach("package:forecast", unload=TRUE)
getwd()
install.packages("forecast")
2.
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
fit1<-train(diagnosis~.,data=training,method="rf",type="class")
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
fit1<-train(diagnosis~.,data=training,method="rf",type="class")
set.seed(62433)
fit2<-train(diagnosis~.,data=training,method="gbm")
set.seed(62433)
fit3<-train(diagnosis~.,data=training,method="lda")
set.seed(62433)
pred1<-predict(fit1,newdata=testing)
set.seed(62433)
pred2<-predict(fit2,newdata=testing)
set.seed(62433)
pred3<-predict(fit3,newdata=testing)
#Stacking
set.seed(62433)
predDF<-data.frame(pred1,pred2,pred3,diagnosis=testing$diagnosis)
set.seed(62433)
combModFit <- train(diagnosis ~.,method="rf",data=predDF)
set.seed(62433)
combPred <- predict(combModFit,predDF)
set.seed(62433)
confusionMatrix(combPred,testing$diagnosis) #.8171
confusionMatrix(pred1,testing$diagnosis)$overall #.768
confusionMatrix(pred2,testing$diagnosis)$overall #.805
confusionMatrix(pred3,testing$diagnosis)$overall #.768
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
fit1<-train(diagnosis~.,data=training,method="rf",type="class")
set.seed(62433)
fit2<-train(diagnosis~.,data=training,method="gbm")
set.seed(62433)
fit3<-train(diagnosis~.,data=training,method="lda")
set.seed(62433)
pred1<-predict(fit1,newdata=testing)
set.seed(62433)
pred2<-predict(fit2,newdata=testing)
set.seed(62433)
pred3<-predict(fit3,newdata=testing)
set.seed(62433)
predDF<-data.frame(pred1,pred2,pred3,diagnosis=training$diagnosis)
set.seed(62433)
combModFit <- train(diagnosis ~.,method="rf",data=predDF)
shiny::runApp('C:/Users/Michael/SkyDrive/Coursera/GitHub/HealthMap')
showLogs()
??showLogs()
?colSums
?show
?dgamma
?skeleton
?skeleton()
??skeleton
install.packages("skeleton")
library("utils", lib.loc="C:/Program Files/R/R-3.1.1/library")
?skeleton.package
?showMethods
?getMethod
?model.load
??model.load
?model.require
??model.require
install.packages("yhat")
?model.require
??model.require
install.packages("yhatr")
??model.require
??model
library("yhatr", lib.loc="~/R/win-library/3.1")
yhat.config <- c(
username = "your username",
apikey = "your apikey",
env = "http://cloud.yhathq.com/"
)
iris$Sepal.Width_sq <- iris$Sepal.Width^2
fit <- glm(I(Species)=="virginica" ~ ., data=iris)
model.require <- function() {
# require("randomForest")
}
yhat.deploy("irisModel")
yhat.deploy
yhat.verify
?model
?model.require
??model.require
yhat.predict
?predict
detach("package:yhatr", unload=TRUE)
predict
predict()
colSums()
?colSums
?gvisGeoChart
??gvisGeoChart
shiny::runApp('C:/Users/Michael/SkyDrive/Coursera/GitHub/Health2')
YTD <- read.csv("YTD.csv",stringsAsFactors=FALSE)
##YTD First
colnames(YTD)<-as.character(YTD[4,])
#Eliminate Extra Header Rows
YTD2<-YTD[5:29,]
#Just FULL YEAR section AND Countries
YTD3<-cbind("Rank"=c(1:25),"COUNTRY/REGION"=YTD2$COUNTRY,YTD2[,15:18])
#Rownames orderly again (if this matters I don't know yet)
rownames(YTD3)<-c(1:25)
##
##HTD Now
HTD <- read.csv("HTD.csv",stringsAsFactors=FALSE)
colnames(HTD)<-as.character(HTD[4,])
#Eliminate Extra Header Rows
HTD2<-HTD[5:29,]
#Just FULL YEAR section AND Countries
HTD3<-cbind("Rank"=c(1:25),"COUNTRY/REGION"=HTD2$COUNTRY,HTD2[,10:12])
#Rownames orderly again (if this matters I don't know yet)
rownames(HTD3)<-c(1:25)
YTD<-YTD3
HTD<-HTD3
#gsub('\\$', '', YTD[,6])
setwd("C:/Users/Michael/SkyDrive/Coursera/GitHub/Health2")
###Pre-Processing
YTD <- read.csv("YTD.csv",stringsAsFactors=FALSE)
##YTD First
colnames(YTD)<-as.character(YTD[4,])
#Eliminate Extra Header Rows
YTD2<-YTD[5:29,]
#Just FULL YEAR section AND Countries
YTD3<-cbind("Rank"=c(1:25),"COUNTRY/REGION"=YTD2$COUNTRY,YTD2[,15:18])
#Rownames orderly again (if this matters I don't know yet)
rownames(YTD3)<-c(1:25)
##
##HTD Now
HTD <- read.csv("HTD.csv",stringsAsFactors=FALSE)
colnames(HTD)<-as.character(HTD[4,])
#Eliminate Extra Header Rows
HTD2<-HTD[5:29,]
#Just FULL YEAR section AND Countries
HTD3<-cbind("Rank"=c(1:25),"COUNTRY/REGION"=HTD2$COUNTRY,HTD2[,10:12])
#Rownames orderly again (if this matters I don't know yet)
rownames(HTD3)<-c(1:25)
YTD<-YTD3
HTD<-HTD3
#gsub('\\$', '', YTD[,6])
##
###
shiny::runApp()
View(YTD)
data<-cbind(YTD," $$ over OP"=gsub('\\$', '', YTD[,6]))
View(data)
class(data[,7])
class(data[19,7])
data[19,7]
data<-cbind(YTD," $$ over OP"=as.numeric(gsub('\\$', '', YTD[,6])))
shiny::runApp()
?adjust
??adjust
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
data<-cbind(HTD," $$ over OP"=as.numeric(gsub('\\$', '', HTD[,6])))
YTD <- read.csv("YTD.csv",stringsAsFactors=FALSE)
##YTD First
colnames(YTD)<-as.character(YTD[4,])
#Eliminate Extra Header Rows
YTD2<-YTD[5:29,]
#Just FULL YEAR section AND Countries
YTD3<-cbind("Rank"=c(1:25),"COUNTRY/REGION"=YTD2$COUNTRY,YTD2[,15:18])
#Rownames orderly again (if this matters I don't know yet)
rownames(YTD3)<-c(1:25)
##
##HTD Now
HTD <- read.csv("HTD.csv",stringsAsFactors=FALSE)
colnames(HTD)<-as.character(HTD[4,])
#Eliminate Extra Header Rows
HTD2<-HTD[5:29,]
#Just FULL YEAR section AND Countries
HTD3<-cbind("Rank"=c(1:25),"COUNTRY/REGION"=HTD2$COUNTRY,HTD2[,10:12])
#Rownames orderly again (if this matters I don't know yet)
rownames(HTD3)<-c(1:25)
YTD<-YTD3
HTD<-HTD3
shiny::runApp()
View(HTD)
View(YTD3)
View(HTD)
View(HTD)
View(data)
data<-cbind(HTD," $$ over OP"=as.numeric(gsub('\\$', '', HTD[,6])))
View(HTD)
shiny::runApp()
#setwd("C:/Users/Michael/SkyDrive/Coursera/GitHub/Health2")
###Pre-Processing
YTD <- read.csv("YTD.csv",stringsAsFactors=FALSE)
##YTD First
colnames(YTD)<-as.character(YTD[4,])
#Eliminate Extra Header Rows
YTD2<-YTD[5:29,]
#Just FULL YEAR section AND Countries
YTD3<-cbind("Rank"=c(1:25),"COUNTRY/REGION"=YTD2$COUNTRY,YTD2[,15:18])
#Rownames orderly again (if this matters I don't know yet)
rownames(YTD3)<-c(1:25)
##
##HTD Now
HTD <- read.csv("HTD.csv",stringsAsFactors=FALSE)
colnames(HTD)<-as.character(HTD[4,])
#Eliminate Extra Header Rows
HTD2<-HTD[5:29,]
#Just FULL YEAR section AND Countries
HTD3<-cbind("Rank"=c(1:25),"COUNTRY/REGION"=HTD2$COUNTRY,HTD2[,10:12])
#Rownames orderly again (if this matters I don't know yet)
rownames(HTD3)<-c(1:25)
View(HTD3)
View(HTD)
View(HTD2)
View(HTD3)
View(HTD)
#setwd("C:/Users/Michael/SkyDrive/Coursera/GitHub/Health2")
###Pre-Processing
YTD <- read.csv("YTD.csv",stringsAsFactors=FALSE)
##YTD First
colnames(YTD)<-as.character(YTD[4,])
#Eliminate Extra Header Rows
YTD2<-YTD[5:29,]
#Just FULL YEAR section AND Countries
YTD3<-cbind("Rank"=c(1:25),"COUNTRY/REGION"=YTD2$COUNTRY,YTD2[,15:18])
#Rownames orderly again (if this matters I don't know yet)
rownames(YTD3)<-c(1:25)
##
##HTD Now
HTD <- read.csv("HTD.csv",stringsAsFactors=FALSE)
colnames(HTD)<-as.character(HTD[4,])
#Eliminate Extra Header Rows
HTD2<-HTD[5:29,]
#Just FULL YEAR section AND Countries
HTD3<-cbind("Rank"=c(1:25),"COUNTRY/REGION"=HTD2$COUNTRY,HTD2[,11:13])
#Rownames orderly again (if this matters I don't know yet)
rownames(HTD3)<-c(1:25)
YTD<-YTD3
HTD<-HTD3
View(HTD)
colnames(HTD)
colnames(HTD[5])
colnames(HTD[5])<-"LCG % pts. over OP"
shiny::runApp()
HTD<-HTD3
colnames(HTD[5])<-"LCG % pts. over OP"
View(HTD)
colnames(HTD[5])
colnames(HTD[5])<-"LCG % pts. over OP"
colnames(HTD[5])
colnames(HTD[5])<-"test"
colnames(HTD[5])
colnames(HTD[5])<-as.character("test")
colnames(HTD[5])
colnames(HTD)
class(colnames(HTD))
dim(colnames(HTD))
length(colnames(HTD))
colnames(HTD)[5]
colnames(HTD)[5]<-"LCG % pts. over OP"
View(HTD)
shiny::runApp()
#setwd("C:/Users/Michael/SkyDrive/Coursera/GitHub/Health2")
###Pre-Processing
YTD <- read.csv("YTD.csv",stringsAsFactors=FALSE)
##YTD First
colnames(YTD)<-as.character(YTD[4,])
#Eliminate Extra Header Rows
YTD2<-YTD[5:29,]
#Just FULL YEAR section AND Countries
YTD3<-cbind("Rank"=c(1:23),"Country/Region"=YTD2$COUNTRY,YTD2[,15:18])
#Rownames orderly again (if this matters I don't know yet)
rownames(YTD3)<-c(1:23)
##
##HTD Now
HTD <- read.csv("HTD.csv",stringsAsFactors=FALSE)
colnames(HTD)<-as.character(HTD[4,])
#Eliminate Extra Header Rows
HTD2<-HTD[5:29,]
#Just FULL YEAR section AND Countries
HTD3<-cbind("Rank"=c(1:23),"Country/Region"=HTD2$COUNTRY,HTD2[,11:13])
#Rownames orderly again (if this matters I don't know yet)
rownames(HTD3)<-c(1:23)
YTD<-YTD3
HTD<-HTD3
colnames(HTD)[5]<-"LCG % pts. over OP"
shiny::runApp()
View(HTD)
YTD <- read.csv("YTD.csv",stringsAsFactors=FALSE)
##YTD First
colnames(YTD)<-as.character(YTD[4,])
#Eliminate Extra Header Rows
YTD2<-YTD[5:29,]
#Just FULL YEAR section AND Countries
YTD3<-cbind("Rank"=c(1:23),"Country/Region"=YTD2$COUNTRY,YTD2[,15:18])
#Rownames orderly again (if this matters I don't know yet)
rownames(YTD3)<-c(1:23)
##
##HTD Now
HTD <- read.csv("HTD.csv",stringsAsFactors=FALSE)
colnames(HTD)<-as.character(HTD[4,])
#Eliminate Extra Header Rows
HTD2<-HTD[5:29,]
#Just FULL YEAR section AND Countries
HTD3<-cbind("Rank"=c(1:23),"Country/Region"=HTD2$COUNTRY,HTD2[,11:13])
#Rownames orderly again (if this matters I don't know yet)
rownames(HTD3)<-c(1:23)
YTD<-YTD3
HTD<-HTD3
colnames(HTD)[5]<-"LCG % pts. over OP"
View(YTD)
#setwd("C:/Users/Michael/SkyDrive/Coursera/GitHub/Health2")
###Pre-Processing
YTD <- read.csv("YTD.csv",stringsAsFactors=FALSE)
##YTD First
colnames(YTD)<-as.character(YTD[4,])
#Eliminate Extra Header Rows
YTD2<-YTD[5:27,]
#Just FULL YEAR section AND Countries
YTD3<-cbind("Rank"=c(1:23),"Country/Region"=YTD2$COUNTRY,YTD2[,15:18])
#Rownames orderly again (if this matters I don't know yet)
rownames(YTD3)<-c(1:23)
##
##HTD Now
HTD <- read.csv("HTD.csv",stringsAsFactors=FALSE)
colnames(HTD)<-as.character(HTD[4,])
#Eliminate Extra Header Rows
HTD2<-HTD[5:27,]
#Just FULL YEAR section AND Countries
HTD3<-cbind("Rank"=c(1:23),"Country/Region"=HTD2$COUNTRY,HTD2[,11:13])
#Rownames orderly again (if this matters I don't know yet)
rownames(HTD3)<-c(1:23)
YTD<-YTD3
HTD<-HTD3
colnames(HTD)[5]<-"LCG % pts. over OP"
#gsub('\\$', '', YTD[,6])
View(HTD)
shiny::runApp()
library("shinyapps", lib.loc="~/R/win-library/3.1")
shiny::runApp()
shiny::runApp()
shiny::runApp()
